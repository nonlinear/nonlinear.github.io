---
title: Philosophy and Simulation
category: book 
date: 2024-05-08 
link: https://www.abebooks.com/9781474252843/Philosophy-Simulation-Emergence-Synthetic-Reason-1474252842/plp
author: Manuel DeLanda
---

## The Emergence of Synthetic Reason

## Introduction Emergence in History

> the absence of novelty in physical interactions meant that explaining their effects could be reduced to deduction from general principles or laws

> But the synthesis of water does produce something new, not new in the absolute sense of something that has never existed before but only in the relative sense that something emerges that was not in the interacting entities acting as causes

> But there are many other physical mechanisms that are ***REMOVED***

> This shape is emergent because the metallic atoms making up the knife must be arranged in a very particular way for it to be triangular

> a capacity may remain only potential if it is never actually exercised.

> very different ontological status between properties and capacities

> when the capacity does become actual it is not as a state, like the state of being sharp, but as an event, an event that is always double: to cut-to be cut.

> while properties can be specified without reference to anything else capacities to affect must always be thought in relation to capacities to be affected

> the ontological relation between properties and capacities displays a complex symmetry

> The main difference between tendencies and capacities is that while the former are typically finite the latter need not be.

> Since neither tendencies nor capacities must be actual to be real it would be tempting to give them the status of possibilities.

> specifying the structure of the space of possibilities

> studied through the imposition of a certain arrangement

> the only discontinuities are the critical points separating the different tendencies.

> the structure of possibility spaces plays as great a role in the explanation of emergence as do mechanisms

> formed a pyramid of progressively ascending grades

> prebiotic soup, bacterial ecosystems, insect intelligence, mammalian memory, primate social strategies, and the emergence of trade, language, and institutional organizations in human communities

## Chapter One: The Storm in the Computer

> But temperature and pressure are in fact irreducible because they are the result of an objective averaging process

> intensive properties

> gradients

> The death of a thunderstorm, in turn, is linked to processes that counteract its sustaining gradients: the higher the air reaches the colder it gets, the more saturated it becomes, and the larger the liquid drops and ice crystals that condense from it

> the form created by the gradient to cancel itself.

> the updraft sucks the air from the center of the tornado greatly reducing the pressure inside of it compared to that of the outside.7

> we can explain how it is born, how it lives, and how it dies

> one scale

> emergent entities at that scale can become the component parts of a whole at a larger scale

> gradients of matter not of energy.

> asymptotic stability.

> Not all oscillating entities possess this kind of stability

> mechanism-independent component

> properties, tendencies, and capacities

> stable emergent property is “indifferent” to local changes in the interactions that give rise to it

> mechanism-independence: if processes as different in detail as a convection cell and a chemical clock can exhibit the same behavior perhaps mathematical equations can also display that behavior.

> geometrically similar.10

> the fact that the geometric similarity has persisted has made the underlying behavioral isomorphism even more problematic

> To everyone’s surprise a central pillar, an anvil, a dome, and a flanking line of clouds spontaneously emerged despite the fact that none of those features had been explicitly modeled

> natural phenomena exhibit a recurrent part-to-whole relation

> This isomorphism has mystified physicists for as long as there has been evidence of its existence

> The ontological status of both tendencies and capacities is therefore different from that of properties

> an unmanifested tendency and an unexercised capacity are not just possible but define a concrete space of possibilities with a definite structure.

> ity. The structure of this space can be conceived as the subset of those points that have a much higher probability to become actual. When we described the mechanism of emergence

> the stability of emergent properties is explained by the structure of a possibility space and the fact that this stability can be displayed by entirely different mechanisms

> and non-metric spaces exemplified by a variety of other geometries: projective, differential, topological.

> When we do this a space ceases to be a set of coordinate addresses and becomes a field of rapidities and slownesses

> The structure of an abstract space, in turn, can be characterized by those properties that remain unchanged when the space is transformed, when it is moved

> rotated, folded, stretched.

> the existence and distribution of special or remarkable points (or sets of such points) called singularities.

> the possibilities with the highest probability of occurring are topological singularities acting as attractors.
Let’s now apply this line of

> To create a mathematical model the first step is to enumerate all the relevant ways in which the process to be modeled is free to change.

> the art of mathematical modeling being based in part on the ability to judge what changes do, and what changes do not, make a difference

> It was by observing the tendency of many of these trajectories to converge on specific areas of state space, to converge on singularities, that the existence of asymptotic stability was first established.15

> a mathematical model can capture the behavior of a material process because the space of possible solutions overlaps the possibility space associated with the material process.

> The two possibility spaces need not be identical but merely overlapping

> Once this ontological commitment has been made the term “singularity” ceases to be a purely mathematical concept and becomes a properly philosophical one.

> If all the matter and energy of the universe ceased to exist, would singularities also disappear (immanent) or would they continue to exist (transcendent)?

> It can be proved, for example, that in a two-dimensional space only certain kinds of singularities exist: four different types of point singularities distinguished from each other by the form of the flow of nearby trajectories (nodes, saddle points, foci, and centers)

> In three-dimensional spaces, the four point singularities are still part of the repertoire but now periodic singularities come in three different forms: stable, unstable, and saddle-shaped loops

> one that can be pictured as a loop that has been repeatedly stretched and folded

> nature of the gradient (thermal, gravitational, mechanical, chemical)

> State space is only one kind of possibility space, a space useful to study tendencies but not capacities.

> entities can exercise their capacities in interaction with a potentially innumerable variety of other entities

> interactions in which capacities are exercised can be staged in a simulation

> until the singular features of the possibility space are made visible.

> how staging a different type of simulated interaction (chemical, biological, social) can tease out the singular structure of their possibility spaces.

## Chapter Two: Cellular Automata and Patterns of Flow

> The simplest of all computing machines, finite state automata, can perform a computation by changing from one state to another in a well-defined sequence without having to store intermediate results.

> cells may be triangular, rectangular, hexagonal, or any shape that exactly tiles the plane so that the cells are connected to one another by sharing edges and corners

> emergent properties, tendencies, and capacities, and

> that are not present in the individual automata

> the tendency to remain in a steady state and the tendency to oscillate between states.

> most initial patterns disappear after a few generations.

> Gliders and other spaceships provide the clearest example of emergence in cellular automata

> There is a collision of 13 gliders, for instance, that synthesizes a pattern more complex than the glider itself: a glider gun

> a finite state automaton represents a capacity minimum while a so-called Turing machine represents a capacity maximum

> computing machines can be built out of basic digital circuits called logical gates

> a simple Turing machine capable of being in three different states and using three symbols to write in its memory tape

> Since this is all a rule does, defining the transition from one state to the next, the total number of rules is the number of states raised to the number of possible configuration of states for a neighborhood

> class IV sandwiched between class II and class III and occupying a zone much smaller than the zones on either side of it.10

> a universal Turing machine is an automaton that can simulate any special purpose Turing machine,

> its memory tape including among other things an executable symbolic description of the automaton it is supposed to simulate.

> the cheaper and more abundant their memory the closer the approximation

> lattice-gas automata

> scientific models take advantage of the decomposability of reality made possible by emergent properties

> the state space for a single molecule is already six-dimensional, the space of possibilities for the whole population being literally unsurveyable

> exports its own disorder elsewhere? In fluid dynamics these situations are called “instabilities” because the existence of a live gradient is unstable

> as the heavy fluid invades and displaces the light one.

> conservation and symmetry

> Symmetry refers to the indifference that the regularities in the behavior of molecular populations display to being transformed in certain ways

> But with lattice-gas automata we can actually follow the molecular population until it reaches a given spatial arrangement

> several runs of the same simulation can be carried out changing the values assigned to certain parameters and tracking the unfolding process to check whether it arrives at the same final state.

> varying them in different runs is equivalent to checking whether the outcome is robust to changes in the assumptions.

> computer simulations may be thought as occupying

> an intermediate position between that of formal theory and laboratory experiment.19

> the chemistry of the prebiotic soup

> those that retain their identity (catalysts) are capable of affecting that synthesis by accelerating it or decelerating it.

## Chapter Three: Artificial Chemistries and the Prebiotic Soup

> an acid–base or Ph gradient

> oxidation–reduction or redox gradient

> trinsically open-ended

> the inherent open-endedness of chemical interactions allows possibilities not originally present in a space to be subsequently added to it.

> molecular recognition, the simplest kind of which is a geometrical complementarity between two different molecules, one acting as a “lock” the other as a “key.”

> Putting together these two capacities yields a catalyst

> pushing it away from equilibrium and creating a gradient.

> if polymers could act as their own catalysts

> Some contemporary proteins, called enzymes, can act as more powerful and specific catalysts than metallic crystals

> the acceleration of bond creation to compensate for the spontaneous destruction promoted by an aqueous environment,

> For enzymes to have this capacity their one-dimensional structure must be folded into a three-dimensional shape with the right geometric features. The

> we are considering possibility spaces that grow explosively as the length of the polymers increases.

> Keeping track of the increase in the number of dimensions can be done by coupling a state space to a graph like the one just discussed

> Thus, metadynamic simulations explore two coupled possibility spaces

> follow the new process until it reaches a new steady state, adjusting

> At that point another steady-state attractor is reached (called a “metadynamical fixed point”

> a singularity representing the long-term tendencies of the entire series of reactions, and it is therefore much more important that all the intervening ones.7

> after this chain has folded into a three-dimensional form, an enzyme is an entity with the capacity to act on other chains breaking them up or gluing them together

> When a computer program is copied from one hard disk to another, for example, it is treated as a mere chain of ones and zeroes, but when it is executed it becomes a procedure that can perform a variety of operations on other chains of ones and zeroes

> a complex program can be built using a part-to-whole relation:

> one as a program (enzyme) and the other as data (target substrate)

> Because recursive function languages have the computational capacity of the most sophisticated automata, and because of the random character of the collisions, this artificial chemistry is referred to as a Turing gas.10

> catalytic closure

## Chapter Four: Genetic Algorithms and the Prebiotic Soup

> for is the relatively simple process through which an RNA molecule can serve as a template for the creation of a copy of itself.

> a new kind of gradient, a gradient of fitness.

> fitness differences act just like temperature differences

> the moment the differences disappear the selection process stops.1

> An RNA molecule is simply a sequence of four possible nucleotides, each member of the set displaying clear tendencies to bond with just another member

> Given these tendencies a sequence of nucleotides can create a copy of itself using a mechanism similar to that of conventional photography: first a “negative” is created as complementary monomers attach themselves one by one to the template, and then a “positive print” is produced from that negative

> the copying errors or mutations that provide the necessary variability to prevent fitness gradients from disappearing do

> the possibility spaces associated with living organisms can become very numerous as the complexity of their part-to-whole organization increases.

> the space of possible genes; the space of possible structural proteins and enzymes that these genes code for; and the space of possible spatial structures and metabolic pathways that the structural proteins and enzymes can form

> the space of possible cell types (such as muscle, bone, nerve, blood); the space of possible tissues and organs these cells can form; and the space of possible organisms these tissues and organs can compose.

> naked RNA has a very simple relation between genotype and phenotype: the unfolded polymer constitutes the former while the folded version and its catalytic capacities constitutes the latter.

> the space of folded forms,

> a smaller space given that several different sequences of nucleotides can end up with equivalent folded forms.3

> every possible polymer is in direct contact with all its one-mutant neighbors and a series of neighbors forms a connected path for evolution to follow

> Fitness refers in this case to the consequences for reproductive success of the catalytic capacities that each polymer would have if it were folded into a three-dimensional shape

> A possibility space of self-replicating entities to which fitness values have been assigned is called a fitness landscape.

> In this case selection pressures alone cannot dislodge the population from the trap

> the “topography” of the fitness landscape must be part of the model

> the qualitative characteristics of a landscape: whether it has a single global optimum or many local optima

> one best catalyst surrounded by mutants declining smoothly in fitness.

> the landscape is structured by many local optima around which fitness decreases steeply. The first extreme makes evolution entirely predictable while the second one makes it entirely unfeasible

> Let’s imagine a particular RNA polymer with very high fitness located at a local optimum with smooth slopes

> the entire set forming a coherent cloud of mutants.

> a non-dominant mutant that is surrounded by very fit ones can out reproduce the dominant one

> At that moment the initial cloud will melt and re-condense around the new singularity

> nevertheless better at finding local optima of higher fitness than a random walk

> As before, it is the intermediate values that yield the interesting cases

> These two factors together determine what is called the error threshold,

> a singularity similar to a phase transition because beyond the threshold the “liquid” cloud tends to “vaporize

> quasi-species existing in the vicinity of the error threshold

> the very least the problem of how to extract energy from environmental

> In genetic algorithms, by contrast, fitness is evaluated from the outside by

> does not emerge from competition but is dictated by rules that translate problem-solving ability into reproductive success.

> The only thing that emerges in simulations using genetic algorithms is specific solutions to specific problems

> The problems to which genetic algorithms are applied have often nothing to do with biology

> a reliable mechanical recipe to perform the folding operation does not yet exist

> we think of a folded RNA polymer as the form produced by a gradient as it dissipates

> check whether stable forms emerge that can become the centers of quasi-species. One simulation

> as we consider more embodied replicators the relation between genotype and phenotype must be modeled in more detail

> simple forms of chemical circuitry (autocatalytic loops) could emerge in a soup of symbol strings belonging to a recursive function language, that is, in a Turing gas

> the overall metabolic task forms the root of the tree while progressively more detailed sub-tasks form the branches of the tree

> In particular, genetic programming can tackle more challenging design problems

> given that complex programs are evolved by recursion, that is, by functions that result from the composition of simpler ones,

> functions that insert a new component (a resistor, a capacitor, an inductor); functions that alter the connectivity

> of those components (the topology of the circuit); and functions that set the intensity (or sizing) of a component, that is, the degree of resistance of a resistor, the capacitance of a capacitor, and so on.

> Any complex function that can be created from the elementary ones by recursion, on the other hand, can be considered

> The final step is to create a fitness function defining the problem to be solved

> isomorphism

> This would involve discovering the topology and sizing of the network, that is, the connectivity of the different reactions and the values of the rates at which they proceed

> the capacity of a population of variable replicators to search a possibility space is indeed real

> In other words, the crossover operator mimics the effect of sexual recombination.

> The string “###1#####0” is called a “schema.”23

> the average fitness of the schema

> If we think of each string in the population as a point in a multidimensional possibility space then a schema with many instances is like a slice (or hyperplane) of that space

> the presence of introns should lower the risk of disruption of exons

## Chapter Five: Genetic Algorithms and Ancient Organisms

> evolution produced many new mechanisms to use energy to perform work, for complex locomotion or for neural control, for instance, but no new major ways of extracting energy from gradients.2

> fermentation, photosynthesis, and respiration

> Using the least efficient process, fermentation, 180 grams of sugar can be broken down to yield 20,000 calories of energy. The

> adding respiration produced a net surplus of bacterial flesh (or “biomass”)

> complexification of food chains

> bacterial biomass itself became a gradient that could be tapped into by newly evolved predatory species

> respiration (the ancestors of mitochondria)

> The interactions between the new creatures and the older bacteria may have started as parasitic and only later developed into a more mutualistic relation as the intimate knowledge that parasites had about their hosts was used for their common benefit. The

> the former parasites had to be replicated in synchrony with their hosts so that their reproductive interests did not diverge.5

> In many contemporary organisms there are enduring symbioses in which bacteria in the guts of larger animals allow the latter to digest food they could not otherwise process, but the microorganisms must be re-ingested every generation.

> This deeper form of mutualistic relation is called endosymbiosis.
Endosymbiosis

> behavioral, population, community, and ecosystem ecology.

> Although each of these spatial scales is distinct enough to be studied by a different field it is important to emphasize that we are dealing here with differences in relative scale

> house an entire ecosystem of microorganisms displaying all four levels of organization

> carrying capacity

> Real populations, of course, need not exist at the singularity but fluctuate around it or periodically overshoot it

> Insects and weeds are often used as examples of the first strategy while large mammals and trees exemplify the second one

> Ecological relations can, in fact, be defined by the effect that the density of one species has on the density of another

> If the densities of both species decrease there is competition. If they both increase the relation is one of mutualism or symbiosis. And finally, if the density of one population grows without affecting that of the other then their relation is one of commensalism.

> asymptotically stable, that is, only if the period of the oscillation has a tendency to return to its original value after an external shock.

> mechanism-independent structure of

> embodied and situated creatures

> we want to model the capacity of the environment to affect the organisms as well as the capacity of the organisms to affect their environment

> Searching for food in an efficient way is important because movement involves an energy cost

> The component of the simulated organisms that transforms information from the sensors into different types of movement is a simple model of a neuron called a “neural net.”

> the disadvantage is that ancient predators did not use neurons to connect sensors and motors but complex biochemical mechanisms

> approach it asymptotically

> new biochemical circuitry that basically exhausted all the known ways of extracting energy from environmental gradients

> different possibility spaces

> The distribution of singularities (fitness optima) in

> although predator and prey species have their own genotypes they influence each other’s fitness

> the coevolution of predators and prey implies that their fitness landscapes are constantly being deformed

> with some “hills” being transformed into “valleys.

> many fitness landscapes may become serially coupled

> evolution itself may limit the length of food chains to avoid a dead end

> transferable sets of genes called plasmids are responsible for the spread of antibiotic resistance in bacteria in the past 70 years

> adhesion interactions

> adhesion tags

> mat-like structures

> promoting specialization

> many organisms achieve reproductive isolation through the possession of special markings

> paramecia the ancestors of which were among the earliest eukaryotes

> the great burst of differentiation known as the “Cambrian explosion.”21

> Once our simulations reach the post-Cambrian period

## Chapter Six: Neural Nets and Insect Intelligence

> To confront this diversity organisms began to develop internal models to guide their behavior

> new kind of biological material, neuronal material

> the capacity to distinguish the relevant from the irrelevant

> the ability to foreground only the opportunities and risks pushing everything else into an undifferentiated background

> An organism like a hydra, for instance, can gradually decrease its response to a stimulus—can become habituated to it—as experience finds it harmless or avoidable

> habituation transforms a significant stimulus into an insignificant one.

> two ancient forms of learning

> Behind these subjective gradients, on the other hand, there are objective ones: concentration gradients of electrically charged substances constantly produced and maintained in the fluids inside and outside neurons.

> The capacity to become habituated to external stimuli can serve as a useful starting point for a philosophical investigation of animal learning

> The key to the conversion of one gradient into another is the selective permeability of a neuron’s membrane to metallic ions

> Although mammals were originally used to prove the existence of this associative capacity it became clear later that insects also possess it.

> only if the conditioned stimulus is in fact predictive of the presence of the unconditioned one

> floral odors should be easier to learn than the shape of flowers since the latter varies with the angle of observation

> less predictive of the presence of food.

> a set of stimuli that tend to co-occur in the presence of flowers

> Classical conditioning, for example, is characterized by a learning curve that displays a clear deceleration

> an association still forms and affects the animal’s behavior once its ability to move has been recovered

> we need simulations in which the computing units interact with one another through excitation and inhibition;

> artificial neural net

> Simply put, a perceptron is a device that maps an input pattern into an output pattern

> The association between input and output patterns is created by training the neural net.

> the training involves stimulating the neural net’s sensors while simultaneously showing it the desired motor response

> tion of input and output patterns is performed many times until a stable configuration of weights in the connections is produced.

> This emergent capacity is explained by the fact that the connections have now specific weights and will transmit activation from the input layer to the output layer in just the way needed to reproduce the output pattern

> The simulation, in fact, did not use genetic algorithms but genetic programming

> snakelike sinusoidal motion; the use of paddles, symmetrical flippers, or even sets of many flippers for swimming;

> complex coordinated movements could emerge without the need for central commands from the brain

> capacity to generalize

> they will produce the reflexive behavior when exposed to either the light or the sound but not to both

> A neural net with hidden layers is called a “multilayer perceptron.”

> no one knew how to train a neural net with multiple layers.

> a progressive convergence on the stable configuration

> back-propagation of error ensuring the convergence on the target pattern through the progressive minimization of this error

> information about the correctness of its current output pattern flows backwards

> stored weight configuration

> the connections between the hidden and output layers

> a non-symbolic representation of sensory stimuli

> emergent non-symbolic representations

> multilayer perceptrons can be used to simulate learning through classical conditioning

> the emergent representations that form in the hidden units will increase the weight of some of the lateral connections and decrease the weight of others

> able to produce the representation of the unconditioned stimulus if given that of the conditioned one and vice versa

> a non-symbolic representation

> a configuration of connection weights that can recreate it when presented with the right input. In other words, what is stored is not a static representation but the means to dynamically reproduce it

> these representations are dispersed or distributed in all the hidden units and are thus closer to a hologram

> they can be superimposed on one another so that the same configuration of weights can serve to reproduce several representations depending on its input

> the capacity of a neural net to generalize

> distributed representations are connected to the world in a non-arbitrary way

> direct accommodation or adaptation to the demands of an external reality

> in a way that one feels compelled to characterize as intentional, that is, as oriented toward external opportunities and risks.

> the degree of mismatch is propagated back to the other layers

> reflexes linking sensory stimuli to adequate motor responses

> the capacity to learn novel behaviors is greatly amplified in animals like birds and mammals because in their case perception and memory go beyond the world of mere stimuli.



## Chapter Seven: Neural Nets and Mammalian Memory

> ever richer substratum for the growth and proliferation of more ethereal entities: memories

> may be incapable of dealing with signification but they surely can attribute significance to the opportunities and risks that their environment affords them

> The type of memory involved in classical conditioning, whether in insects, birds, or mammals, is referred to as “procedural” because of its content’s lack of accessibility outside of the sensory-motor associations that it enables.

> accessible are referred to as “declarative,

> episodic memory

> semantic memory

> non-human mammals and birds do not posses language

> example, must guide their searching behavior by the information they get from different senses

> smell to bring them into close proximity to their target then switching to sight or sound

> The synthesis of information from different sensory modalities is thought to be performed in an animal’s hippocampus

> Damage to the hippocampus, for example, impairs performance on tasks that involve comparing one memory to another or using the content of a memory in a novel context

> back-propagation of error

> object recognition and scene analysis

> Two-way classification experiments

> we are dealing here with partial models of a more complex nervous system.

> The secret is the mapping of relations of similarity into relations of proximity

> objects that resemble each other become neighboring points in the internal possibility space

> The positive or negative reinforcement must be contingent on changes of behavior

> discriminative stimulus

> it can also lead to the formation of superstitious habits bearing no relation to real opportunities and risks

> successive approximation.

> four neural nets were linked together, two for internal reinforcement (pleasure and pain) and two for motor behavior (approach and avoid

> Laboratory evidence for the capacity of birds and mammals to perform scene analysis is more difficult to obtain because of our complete lack of access to their phenomenology

> Propositions are used as component parts of more complex wholes called scripts, structured representations capturing the regularities of routine situations

> A weaker but more defensible argument would be that we have no access to other people’s episodic memories except through verbal reports 